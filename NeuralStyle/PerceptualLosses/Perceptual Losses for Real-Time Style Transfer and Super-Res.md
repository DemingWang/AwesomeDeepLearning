# Perceptual Losses for Real-Time Style Transfer and Super-Resolution

## 创新点

这篇文章主要考虑image transfromation的问题，即输入一张图片，然后将这个图片转换到一个输出图片。对于这类问题：

1. 最近的方法的解决方法就是去训练一个前馈网络，在输出和真实值之间使用per-pixel的损失。
2. 相关工作发现，将图片输入**预训练网络**，提取高层特征，然后在这个特征上计算感知损失函数（perceptual loss function）可以生成高质量的图片。

本文综合了两种方法，对于图像转换任务，提出使用感知损失函数来训练一个前馈网络。

主要考虑两个任务：

1. 图像风格迁移，在达到相似结果的前提下，速度增加了三个数量级。
2. 图像超分辨率



## 几个概念

### 1. 图像转换任务

图像处理领域（输入是一张degraded image）：

1. denoising（noise->denoise）
2. 超分辨率(low resolution->high resolution)
3.  colorization上色(grayscale->color)

计算机视觉（输入是一张RGB图像）：

1. 语义分割
2. 深度估计

对于这类问题，最常用的方法是，训练一个前馈网络，使用per-pixel的损失函数来衡量网络输出和真实值的差异性。



这类方法的缺点：不能捕捉输出和真实值的感知差异（perceptual difference）。举个例子

> 假设两张相同的图片互相之间只是便宜了一个像素，这个时候如果用per-pixel的损失函数，那么值会很大，但是用感知损失函数来算，就会比较小。



### 2. 感知损失函数

给一个已经训练好的网络，喂一张图片，得到高层的特征，将这个特征和真实值计算损失函数就是感知损失函数。



## 模型架构

![Selection_001](/home/pi/Pictures/Selection_001.png)



### 图像转换网络

网络架构要点：

1. 包括上采样和下采样，实际上就是encoder-decoder架构。
2. 使用了残差连接。
3. 对于风格迁移和超分辨率，网络架构的细节有差异。
4. 输入输出大小。对于风格迁移：输入和输出都是3×256×256。超分辨率：输入3 × 288/f × 288/f输出3×288×288 

### 感知损失函数

使用16层的VGG网络，网络预先通过imageNet训练好。

### 简单的损失函数

