---
typora-copy-images-to: pics
---

# 独辟蹊径的目标检测新算法：CornerNet

# 可能开启目标检测新时代：CornerNet

CornerNet是ECCV的一篇新文章，这篇提出了一种全新的目标检测思路，将bounding box的检测问题转为关键点的检测问题。这个思路其实很简单，因为bouding box是一个矩形，这个矩形可以由左上角和右上角两个关键点唯一确定，那这样是不是就可以将bounding box（xywh）的预测问题转为关键点检测问题？这篇文章告诉我们是可以的，而且最牛逼的是，它的精度可以超越一阶段目标检测算法，达到二阶段算法的精度，同时还比二阶段算法快。

下面介绍这篇文章。

## Anchor的缺点

作者一上来就批评了目前目标检测算法中使用的anchor技术，说它有两个缺点。

首先，为了让anchor能和物体的bounding box匹配，需要设置非常多的anchor，比如DSSD这个算法就用到了超过40k个anchor，RetinaNet就用到超过100k的anchor。尽管设置了这么多anchor，但是实际上，真正能够和物体bounding box匹配的anchor是很少的，这就造成了严重的正负样本不平衡的问题，同时，训练速度也会变慢。

其次，anchor的设计也是一件很麻烦的事情，需要设置很多超参数，比如大小，长宽比等等。通常的目标检测算法都是在VOC，COCO这些目标检测数据集中来做实验的，因此也是根据这些数据来设计anchor的。假设我们现在要训练自己的数据集，而自己的数据集具有自己的特性，比如物体的大小和长宽比处在特定的范围，这个时候我们还得去设计适用于这套数据的anchor，这样显然是很蛮烦的。

说了anchor这么多的不好，作者实际上就想说，我要抛弃anchor，另辟蹊径！

## CornetNet整体思路

CornetNet是一个一阶段的算法，整个算法框架如下图：

![1533864404079](pics/1533864404079.png)

首先，CornerNet预测bounding box的左上角和右下角两个关键点。注意是关键点，而不是坐标点，熟悉人体姿态估计的都知道，预测关键点通常是这个点的热图，而预测坐标点是预测xy坐标。

但是预测单单预测关键点还不够。假设一张图片上有多个物体，你预测出了所有物体的关键点，那么你怎么知道某个物体的左上角关键点和哪个右下角关键点匹配呢？没办法知道。为了解决这个问题，出了预测每个关键点，还会附带预测这个关键点对应的嵌入向量（embedding vector），不要被嵌入这个词迷惑，你把嵌入向量当做向量就好了。如果左上角关键点和右下角关键点属于同一个bounding box，那么这两个关键点的嵌入向量最相似（如上图所示），这样就可以解决以上的问题了。

另外，Cornet还提出了一个全新的pooling方法叫做corner pooling，可以更好地定位bounding box的关键点。考虑这样一个问题，很多情况下，关键点并不能由局部特征（local evidence）来决定，比如说下图中的这些红色关键点，它们旁边都是没有物体的特征的，所以直接预测这些关键点可能是不准的。想象一下，如果是人来判断这些关键点会怎么做，我们首先从水平方向上去看一下物体的最高点或者最低点，然后从竖直方向去看一下物体的最左边的点或者最右边的点。受这个启发，作者corner pooling。

![1533864674006](pics/1533864674006.png)



### 检测关键点

