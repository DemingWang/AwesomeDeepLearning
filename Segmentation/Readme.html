<!doctype html>
<html>
<head>
<meta charset='UTF-8'><meta name='viewport' content='width=device-width initial-scale=1'>
<title>Readme.md</title><link href='http://fonts.googleapis.com/css?family=Open+Sans:400italic,700italic,700,400&subset=latin,latin-ext' rel='stylesheet' type='text/css' /><style type='text/css'>html {overflow-x: initial !important;}:root { --bg-color: #ffffff; --text-color: #333333; --code-block-bg-color: inherit; }
html { font-size: 14px; background-color: var(--bg-color); color: var(--text-color); font-family: "Helvetica Neue", Helvetica, Arial, sans-serif; -webkit-font-smoothing: antialiased; }
body { margin: 0px; padding: 0px; height: auto; bottom: 0px; top: 0px; left: 0px; right: 0px; font-size: 1rem; line-height: 1.42857; overflow-x: hidden; background: inherit; }
a:active, a:hover { outline: 0px; }
.in-text-selection, ::selection { background: rgb(181, 214, 252); text-shadow: none; }
#write { margin: 0px auto; height: auto; width: inherit; word-break: normal; word-wrap: break-word; position: relative; padding-bottom: 70px; white-space: pre-wrap; overflow-x: visible; contain: content; }
.for-image #write { padding-left: 8px; padding-right: 8px; }
body.typora-export { padding-left: 30px; padding-right: 30px; }
@media screen and (max-width: 500px) {
  body.typora-export { padding-left: 0px; padding-right: 0px; }
  .CodeMirror-sizer { margin-left: 0px !important; }
  .CodeMirror-gutters { display: none !important; }
}
.typora-export #write { margin: 0px auto; }
#write > p:first-child, #write > ul:first-child, #write > ol:first-child, #write > pre:first-child, #write > blockquote:first-child, #write > div:first-child, #write > table:first-child { margin-top: 30px; }
#write li > table:first-child { margin-top: -20px; }
img { max-width: 100%; vertical-align: middle; }
input, button, select, textarea { color: inherit; font-style: inherit; font-variant: inherit; font-weight: inherit; font-stretch: inherit; font-size: inherit; line-height: inherit; font-family: inherit; }
input[type="checkbox"], input[type="radio"] { line-height: normal; padding: 0px; }
::before, ::after, * { box-sizing: border-box; }
#write p, #write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write div, #write pre { width: inherit; }
#write p, #write h1, #write h2, #write h3, #write h4, #write h5, #write h6 { position: relative; }
h1 { font-size: 2rem; }
h2 { font-size: 1.8rem; }
h3 { font-size: 1.6rem; }
h4 { font-size: 1.4rem; }
h5 { font-size: 1.2rem; }
h6 { font-size: 1rem; }
p { -webkit-margin-before: 1rem; -webkit-margin-after: 1rem; -webkit-margin-start: 0px; -webkit-margin-end: 0px; }
.typora-export p { white-space: normal; }
.mathjax-block { margin-top: 0px; margin-bottom: 0px; -webkit-margin-before: 0rem; -webkit-margin-after: 0rem; }
.hidden { display: none; }
.md-blockmeta { color: rgb(204, 204, 204); font-weight: bold; font-style: italic; }
a { cursor: pointer; }
sup.md-footnote { padding: 2px 4px; background-color: rgba(238, 238, 238, 0.701961); color: rgb(85, 85, 85); border-radius: 4px; }
#write input[type="checkbox"] { cursor: pointer; width: inherit; height: inherit; margin: 4px 0px 0px; }
tr { break-inside: avoid; break-after: auto; }
thead { display: table-header-group; }
table { border-collapse: collapse; border-spacing: 0px; width: 100%; overflow: auto; break-inside: auto; text-align: left; }
table.md-table td { min-width: 80px; }
.CodeMirror-gutters { border-right: 0px; background-color: inherit; }
.CodeMirror { text-align: left; }
.CodeMirror-placeholder { opacity: 0.3; }
.CodeMirror pre { padding: 0px 4px; }
.CodeMirror-lines { padding: 0px; }
div.hr:focus { cursor: none; }
pre { white-space: pre-wrap; }
.CodeMirror-gutters { margin-right: 4px; }
.md-fences { font-size: 0.9rem; display: block; break-inside: avoid; text-align: left; overflow: visible; white-space: pre; background: var(--code-block-bg-color); position: relative !important; }
.md-diagram-panel { width: 100%; margin-top: 10px; text-align: center; padding-top: 0px; padding-bottom: 8px; overflow-x: auto; }
.md-fences .CodeMirror.CodeMirror-wrap { top: -1.6em; margin-bottom: -1.6em; }
.md-fences.mock-cm { white-space: pre-wrap; }
.show-fences-line-number .md-fences { padding-left: 0px; }
.show-fences-line-number .md-fences.mock-cm { padding-left: 40px; }
.footnotes { opacity: 0.8; font-size: 0.9rem; padding-top: 1em; padding-bottom: 1em; }
.footnotes + .footnotes { margin-top: -1em; }
.md-reset { margin: 0px; padding: 0px; border: 0px; outline: 0px; vertical-align: top; background: transparent; text-decoration: none; text-shadow: none; float: none; position: static; width: auto; height: auto; white-space: nowrap; cursor: inherit; -webkit-tap-highlight-color: transparent; line-height: normal; font-weight: normal; text-align: left; box-sizing: content-box; direction: ltr; }
li div { padding-top: 0px; }
blockquote { margin: 1rem 0px; }
li p, li .mathjax-block { margin: 0.5rem 0px; }
li { margin: 0px; position: relative; }
blockquote > :last-child { margin-bottom: 0px; }
blockquote > :first-child { margin-top: 0px; }
.footnotes-area { color: rgb(136, 136, 136); margin-top: 0.714rem; padding-bottom: 0.143rem; }
@media print {
  html, body { border: 1px solid transparent; height: 99%; break-after: avoid; break-before: avoid; }
  .typora-export * { -webkit-print-color-adjust: exact; }
  h1, h2, h3, h4, h5, h6 { break-after: avoid-page; orphans: 2; }
  p { orphans: 4; }
  html.blink-to-pdf { font-size: 13px; }
  .typora-export #write { padding-left: 1cm; padding-right: 1cm; padding-bottom: 0px; break-after: avoid; }
  .typora-export #write::after { height: 0px; }
  @page { margin: 20mm 0mm; }
}
.footnote-line { margin-top: 0.714em; font-size: 0.7em; }
a img, img a { cursor: pointer; }
pre.md-meta-block { font-size: 0.8rem; min-height: 2.86rem; white-space: pre-wrap; background: rgb(204, 204, 204); display: block; overflow-x: hidden; }
p .md-image:only-child { display: inline-block; width: 100%; text-align: center; }
#write .MathJax_Display { margin: 0.8em 0px 0px; }
.mathjax-block { white-space: pre; overflow: hidden; width: 100%; }
p + .mathjax-block { margin-top: -1.143rem; }
.mathjax-block:not(:empty)::after { display: none; }
[contenteditable="true"]:active, [contenteditable="true"]:focus { outline: none; box-shadow: none; }
.task-list { list-style-type: none; }
.task-list-item { position: relative; padding-left: 1em; }
.task-list-item input { position: absolute; top: 0px; left: 0px; }
.math { font-size: 1rem; }
.md-toc { min-height: 3.58rem; position: relative; font-size: 0.9rem; border-radius: 10px; }
.md-toc-content { position: relative; margin-left: 0px; }
.md-toc::after, .md-toc-content::after { display: none; }
.md-toc-item { display: block; color: rgb(65, 131, 196); }
.md-toc-item a { text-decoration: none; }
.md-toc-inner:hover { }
.md-toc-inner { display: inline-block; cursor: pointer; }
.md-toc-h1 .md-toc-inner { margin-left: 0px; font-weight: bold; }
.md-toc-h2 .md-toc-inner { margin-left: 2em; }
.md-toc-h3 .md-toc-inner { margin-left: 4em; }
.md-toc-h4 .md-toc-inner { margin-left: 6em; }
.md-toc-h5 .md-toc-inner { margin-left: 8em; }
.md-toc-h6 .md-toc-inner { margin-left: 10em; }
@media screen and (max-width: 48em) {
  .md-toc-h3 .md-toc-inner { margin-left: 3.5em; }
  .md-toc-h4 .md-toc-inner { margin-left: 5em; }
  .md-toc-h5 .md-toc-inner { margin-left: 6.5em; }
  .md-toc-h6 .md-toc-inner { margin-left: 8em; }
}
a.md-toc-inner { font-size: inherit; font-style: inherit; font-weight: inherit; line-height: inherit; }
.footnote-line a:not(.reversefootnote) { color: inherit; }
.md-attr { display: none; }
.md-fn-count::after { content: "."; }
.md-tag { opacity: 0.5; }
.md-comment { color: rgb(162, 127, 3); opacity: 0.8; font-family: monospace; }
code { text-align: left; }
h1 .md-tag, h2 .md-tag, h3 .md-tag, h4 .md-tag, h5 .md-tag, h6 .md-tag { font-weight: initial; opacity: 0.35; }
a.md-print-anchor { border-width: initial !important; border-style: none !important; border-color: initial !important; display: inline-block !important; position: absolute !important; width: 1px !important; right: 0px !important; outline: none !important; background: transparent !important; text-decoration: initial !important; text-shadow: initial !important; }
.md-inline-math .MathJax_SVG .noError { display: none !important; }
.mathjax-block .MathJax_SVG_Display { text-align: center; margin: 1em 0em; position: relative; text-indent: 0px; max-width: none; max-height: none; min-height: 0px; min-width: 100%; width: auto; display: block !important; }
.MathJax_SVG_Display, .md-inline-math .MathJax_SVG_Display { width: auto; margin: inherit; display: inline-block !important; }
.MathJax_SVG .MJX-monospace { font-family: monospace; }
.MathJax_SVG .MJX-sans-serif { font-family: sans-serif; }
.MathJax_SVG { display: inline; font-style: normal; font-weight: normal; line-height: normal; zoom: 90%; text-indent: 0px; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0px; min-height: 0px; border: 0px; padding: 0px; margin: 0px; }
.MathJax_SVG * { transition: none; }
.md-diagram-panel > svg { max-width: 100%; }
[lang="flow"] svg, [lang="mermaid"] svg { max-width: 100%; }


:root { --side-bar-bg-color: #fafafa; --control-text-color: #777; }
@font-face { font-family: "Open Sans"; font-style: normal; font-weight: normal; src: local("Open Sans Regular"), url("./github/400.woff") format("woff"); }
@font-face { font-family: "Open Sans"; font-style: italic; font-weight: normal; src: local("Open Sans Italic"), url("./github/400i.woff") format("woff"); }
@font-face { font-family: "Open Sans"; font-style: normal; font-weight: bold; src: local("Open Sans Bold"), url("./github/700.woff") format("woff"); }
@font-face { font-family: "Open Sans"; font-style: italic; font-weight: bold; src: local("Open Sans Bold Italic"), url("./github/700i.woff") format("woff"); }
html { font-size: 16px; }
body { font-family: "Open Sans", "Clear Sans", "Helvetica Neue", Helvetica, Arial, sans-serif; color: rgb(51, 51, 51); line-height: 1.6; }
#write { max-width: 860px; margin: 0px auto; padding: 20px 30px 100px; }
#write > ul:first-child, #write > ol:first-child { margin-top: 30px; }
body > :first-child { margin-top: 0px !important; }
body > :last-child { margin-bottom: 0px !important; }
a { color: rgb(65, 131, 196); }
h1, h2, h3, h4, h5, h6 { position: relative; margin-top: 1rem; margin-bottom: 1rem; font-weight: bold; line-height: 1.4; cursor: text; }
h1:hover a.anchor, h2:hover a.anchor, h3:hover a.anchor, h4:hover a.anchor, h5:hover a.anchor, h6:hover a.anchor { text-decoration: none; }
h1 tt, h1 code { font-size: inherit; }
h2 tt, h2 code { font-size: inherit; }
h3 tt, h3 code { font-size: inherit; }
h4 tt, h4 code { font-size: inherit; }
h5 tt, h5 code { font-size: inherit; }
h6 tt, h6 code { font-size: inherit; }
h1 { padding-bottom: 0.3em; font-size: 2.25em; line-height: 1.2; border-bottom: 1px solid rgb(238, 238, 238); }
h2 { padding-bottom: 0.3em; font-size: 1.75em; line-height: 1.225; border-bottom: 1px solid rgb(238, 238, 238); }
h3 { font-size: 1.5em; line-height: 1.43; }
h4 { font-size: 1.25em; }
h5 { font-size: 1em; }
h6 { font-size: 1em; color: rgb(119, 119, 119); }
p, blockquote, ul, ol, dl, table { margin: 0.8em 0px; }
li > ol, li > ul { margin: 0px; }
hr { height: 4px; padding: 0px; margin: 16px 0px; background-color: rgb(231, 231, 231); border-width: 0px 0px 1px; border-style: none none solid; border-top-color: initial; border-right-color: initial; border-left-color: initial; border-image: initial; overflow: hidden; box-sizing: content-box; border-bottom-color: rgb(221, 221, 221); }
body > h2:first-child { margin-top: 0px; padding-top: 0px; }
body > h1:first-child { margin-top: 0px; padding-top: 0px; }
body > h1:first-child + h2 { margin-top: 0px; padding-top: 0px; }
body > h3:first-child, body > h4:first-child, body > h5:first-child, body > h6:first-child { margin-top: 0px; padding-top: 0px; }
a:first-child h1, a:first-child h2, a:first-child h3, a:first-child h4, a:first-child h5, a:first-child h6 { margin-top: 0px; padding-top: 0px; }
h1 p, h2 p, h3 p, h4 p, h5 p, h6 p { margin-top: 0px; }
li p.first { display: inline-block; }
ul, ol { padding-left: 30px; }
ul:first-child, ol:first-child { margin-top: 0px; }
ul:last-child, ol:last-child { margin-bottom: 0px; }
blockquote { border-left: 4px solid rgb(221, 221, 221); padding: 0px 15px; color: rgb(119, 119, 119); }
blockquote blockquote { padding-right: 0px; }
table { padding: 0px; word-break: initial; }
table tr { border-top: 1px solid rgb(204, 204, 204); margin: 0px; padding: 0px; }
table tr:nth-child(2n) { background-color: rgb(248, 248, 248); }
table tr th { font-weight: bold; border: 1px solid rgb(204, 204, 204); text-align: left; margin: 0px; padding: 6px 13px; }
table tr td { border: 1px solid rgb(204, 204, 204); text-align: left; margin: 0px; padding: 6px 13px; }
table tr th:first-child, table tr td:first-child { margin-top: 0px; }
table tr th:last-child, table tr td:last-child { margin-bottom: 0px; }
.CodeMirror-gutters { border-right: 1px solid rgb(221, 221, 221); }
.md-fences, code, tt { border: 1px solid rgb(221, 221, 221); background-color: rgb(248, 248, 248); border-radius: 3px; font-family: Consolas, "Liberation Mono", Courier, monospace; padding: 2px 4px 0px; font-size: 0.9em; }
.md-fences { margin-bottom: 15px; margin-top: 15px; padding: 8px 1em 6px; }
.task-list { padding-left: 0px; }
.task-list-item { padding-left: 32px; }
.task-list-item input { top: 3px; left: 8px; }
@media screen and (min-width: 914px) {
}
@media print {
  html { font-size: 13px; }
  table, pre { break-inside: avoid; }
  pre { word-wrap: break-word; }
}
.md-fences { background-color: rgb(248, 248, 248); }
#write pre.md-meta-block { padding: 1rem; font-size: 85%; line-height: 1.45; background-color: rgb(247, 247, 247); border: 0px; border-radius: 3px; color: rgb(119, 119, 119); margin-top: 0px !important; }
.mathjax-block > .code-tooltip { bottom: 0.375rem; }
#write > h3.md-focus::before { left: -1.5625rem; top: 0.375rem; }
#write > h4.md-focus::before { left: -1.5625rem; top: 0.285714rem; }
#write > h5.md-focus::before { left: -1.5625rem; top: 0.285714rem; }
#write > h6.md-focus::before { left: -1.5625rem; top: 0.285714rem; }
.md-image > .md-meta { border: 1px solid rgb(221, 221, 221); border-radius: 3px; font-family: Consolas, "Liberation Mono", Courier, monospace; padding: 2px 4px 0px; font-size: 0.9em; color: inherit; }
.md-tag { color: inherit; }
.md-toc { margin-top: 20px; padding-bottom: 20px; }
.sidebar-tabs { border-bottom: none; }
#typora-quick-open { border: 1px solid rgb(221, 221, 221); background-color: rgb(248, 248, 248); }
#typora-quick-open-item { background-color: rgb(250, 250, 250); border-color: rgb(254, 254, 254) rgb(229, 229, 229) rgb(229, 229, 229) rgb(238, 238, 238); border-style: solid; border-width: 1px; }
#md-notification::before { top: 10px; }
.on-focus-mode blockquote { border-left-color: rgba(85, 85, 85, 0.117647); }
header, .context-menu, .megamenu-content, footer { font-family: "Segoe UI", Arial, sans-serif; }
.file-node-content:hover .file-node-icon, .file-node-content:hover .file-node-open-state { visibility: visible; }
.mac-seamless-mode #typora-sidebar { background-color: var(--side-bar-bg-color); }
.md-lang { color: rgb(180, 101, 77); }






</style>
</head>
<body class='typora-export' >
<div  id='write'  class = 'is-node'><h1><a name='header-n0' class='md-header-anchor '></a>语义分割总结</h1><p>参考：</p><ol start='' ><li><a href='http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#dilation'>A 2017 Guide to Semantic Segmentation with Deep Learning</a></li><li><a href='https://arxiv.org/abs/1704.06857'>A Review on Deep Learning Techniques Applied to Semantic Segmentation</a> </li></ol><h2><a name='header-n11' class='md-header-anchor '></a>一、什么是语义分割</h2><p>​	语义分割是在像素级别上的分类，属于同一类的像素都要被归为一类，因此语义分割是从像素级别来理解图像的。比如说如下的照片，属于人的像素都要分成一类，属于摩托车的像素也要分成一类，除此之外还有背景像素也被分为一类。注意语义分割不同于实例分割，举例来说，如果一张照片中有多个人，对于语义分割来说，只要将所由人的像素都归为一类，但是实例分割还要将不同人的像素归为不同的类。也就是说实例分割比语义分割更进一步。</p><p><img src='./pics/motor.jpg' alt='motor' /></p><p>图1(a). 原图</p><p><img src='./pics/21_class.png' alt='21_class' /></p><p>图1(b). 分割结果</p><h2><a name='header-n22' class='md-header-anchor '></a>二、语义分割的思路</h2><h3><a name='header-n23' class='md-header-anchor '></a>1.传统方法</h3><p>在深度学习方法流行之前，TextonForest和基于随机森林分类器等语义分割方法是用得比较多的方法。不过在深度卷积网络流行之后，深度学习方法比传统方法提升了很多，所以这里就不详细讲传统方法了。</p><h3><a name='header-n26' class='md-header-anchor '></a>2.深度学习方法</h3><p>深度学习方法在语义分割上得到了巨大成功，深度学习方法解决语义分割问题可以概括为几种思路。下面进行详细介绍。</p><p><strong>Patch classification</strong></p><p>最初的深度学习方法应用于图像分割就是Patch classification。Patch classification方法，顾名思义，图像是切成块喂给深度模型的，然后对像素进行分类。使用图像块的主要原因是因为全连接层需要固定大小的图像。</p><p><strong>全卷积方法</strong></p><p>2014年，全卷积网络（FCN）横空出世，FCN将网络全连接层用卷积取代，因此使任意图像大小的输入都变成可能，而且速度比Patch classification方法快很多。</p><p>尽管移除了全连接层，但是CNN模型用于语义分割还存在一个问题，就是下采样操作（比如，pooling）。pooling操作可以扩大感受野因而能够很好地整合上下文信息（context中文称为语境或者上下文，通俗的理解就是综合了更多的信息来进行决策），对high-level的任务（比如分类），这是很有效的。但同时，由于pooling下采样操作，使得分辨率降低，因此削弱了位置信息，而语义分割中需要score map和原图对齐，因此需要丰富的位置信息。目前的文献中主要有两种不同的架构来解决这个问题。</p><p><strong>encoder-decoder架构</strong></p><p>第一中架构就是encoder-decoder架构。encoder由于pooling逐渐减少空间维度，而decoder逐渐恢复空间维度和细节信息。通常从encoder到decoder还有shortcut connetction（捷径连接，也就是跨层连接）。其中U-net就是这种架构很流行的一种，如下图：</p><p><img src='./pics/unet.png' alt='unet' /></p><p><strong>空洞卷积</strong></p><p>第二种架构叫做dilated/atrous （空洞卷积），这种结构代替了pooling，一方面它可以保持空间分辨率，另外一方面它由于可以扩大感受野因而可以很好地整合上下文信息。如下图：</p><p><img src='./pics/dilated_conv.png' alt='dilated_conv' /></p><p><strong>条件随机场</strong></p><p>除了以上思路，还有一种对分割结果进行后处理的方法，那就是条件随机场(Conditional Random Fields (CRFs))后处理用来改善分割效果。DeepLab系列文章基本都采用这种后处理方法，可以较好地改善分割结果，如下图：</p><p><img src='./pics/CRF.png' alt='CRF' /></p><h2><a name='header-n57' class='md-header-anchor '></a>三、深度学习语义分割方法</h2><h3><a name='header-n58' class='md-header-anchor '></a>方法总览</h3><p>现在的深度学习语义分割模型基本上都是基于FCN发展而来的，它是开山鼻祖，一张图概括FCN的延伸方法：</p><p><img src='./pics/summary.png' alt='summary' /></p><p><strong>各方法的详细信息</strong></p><p><img src='./pics/table-method.png' alt='table-method' /></p><h3><a name='header-n67' class='md-header-anchor '></a>各方法简要介绍</h3><p>下面总结一些从FCN进行改进的几种架构：</p><ol start='' ><li><a href='http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#fcn'>FCN</a></li><li><a href='http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#segnet'>SegNet</a></li><li><a href='http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#dilation'>Dilated Convolutions</a></li><li><a href='http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#deeplab'>DeepLab (v1 &amp; v2)</a></li><li><a href='http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#refinenet'>RefineNet</a></li><li><a href='http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#pspnet'>PSPNet</a></li><li><a href='http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#large-kernel'>Large Kernel Matters</a></li><li><a href='http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review#deeplabv3'>DeepLab v3</a></li></ol><h4><a name='header-n95' class='md-header-anchor '></a>1. FCN</h4><p><strong>论文信息</strong></p><blockquote><p>Fully Convolutional Networks for Semantic Segmentation</p><p>Submitted on 14 Nov 2014</p><p><a href='https://arxiv.org/abs/1411.4038'>Arxiv Link</a></p></blockquote><p><strong>主要贡献</strong></p><ol start='' ><li>使端对端的卷积语义分割网络变得流行起来。</li><li>通过deconvolutional layers进行上采样。</li><li>通过skip connection改善了上采样的粗糙度。</li></ol><p><strong>概要</strong></p><ol start='' ><li><strong>全卷积化(Fully Convolutional)</strong>：用于解决逐像素(pixel-wise)的预测问题。通过将基础网络(例如VGG)最后面几个全连接层换成卷积层，可实现任意大小的图像输入，并且输出图像大小与输入相对应；</li><li><strong>反卷积(deconvolution)</strong> ：上采样操作，用于恢复图片尺寸，方便后续进行逐像素预测;</li><li><strong>跳跃结构(skip architecture)</strong>：用于融合高低层特征信息。通过跨层连接的结构，结合了网络浅层的细(fine-grain)粒度信息信息以及深层的粗糙(coarse)信息，以实现精准的分割任务。</li></ol><p><em>Benchmarks (VOC2012)</em>:</p><table><thead><tr><th>Score</th><th>Comment</th><th>Source</th></tr></thead><tbody><tr><td>62.2</td><td>-</td><td><a href='http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?cls=mean&challengeid=11&compid=6&submid=6103#KEY_FCN-8s'>leaderboard</a></td></tr><tr><td>67.2</td><td>More momentum. Not described in paper</td><td><a href='http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?cls=mean&challengeid=11&compid=6&submid=6103#KEY_FCN-8s-heavy'>leaderboard</a></td></tr></tbody></table><p>评论：</p><p>FCN是基于深度学习的语义分割的开山之作，尽管现在很多方法都超越了FCN，但它的思想仍然有很重要的意义。</p><h4><a name='header-n148' class='md-header-anchor '></a>2. Segnet</h4><p><strong>论文信息</strong></p><blockquote><p>SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation</p><p>Submitted on 2 Nov 2015</p><p><a href='https://arxiv.org/abs/1511.00561'>Arxiv Link</a></p></blockquote><p><strong>主要贡献</strong></p><ul><li>使用Maxpooling indices来增强位置信息。</li></ul><p><strong>简要概述</strong></p><p>FCN的upconvolution层+shortcut connections产生的分割图比较粗糙，因此SegNet增加了更多的shortcut connections。不过，SegNet并不是直接将encoder的特征进行直接复制，而是对maxpooling中的indices进行复制，这使得SegNet的效率更高。</p><p><img src='./pics/segnet.png' alt='segnet' /></p><p>maxpooling 的indices复制原理如下：</p><p><img src='./pics/poolingindex.png' alt='poolingindex' /></p><p><strong>Benchmarks (VOC2012)</strong></p><table><thead><tr><th>Score</th><th>Comment</th><th>Source</th></tr></thead><tbody><tr><td>59.9</td><td>-</td><td><a href='http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&compid=6#KEY_SegNet'>leaderboard</a></td></tr></tbody></table><p><strong>评论</strong></p><ul><li>FCN和SegNet都是encoder-decoder架构。</li><li>SegNet的benchmark表现太差了，不建议用这个网络。</li></ul><h4><a name='header-n194' class='md-header-anchor '></a>3. Dilated convolution</h4><p><strong>论文信息</strong></p><blockquote><p>Multi-Scale Context Aggregation by Dilated Convolutions</p><p>Submitted on 23 Nov 2015</p><p><a href='https://arxiv.org/abs/1511.07122'>Arxiv Link</a></p></blockquote><p><strong>创新点</strong></p><ol start='' ><li>使用空洞卷积用来进行稠密预测（dense prediction）。</li><li>提出上下文模块（context module），使用空洞卷积（Dilated Convolutions）来进行多尺度信息的的整合。</li></ol><p><strong>简要解释</strong></p><p>pooling操作可以增大感受野，对于图像分类任务来说这有很大好处，但由于pooling操作降低了分辨率，这对语义分割来说很不利。因此作者提出一种叫做dilated convolution的操作来解决这个问题。dilated卷积(在deeplab中称为atrous卷积)。可以很好地提升感受野的同时可以保持空间分辨率。</p><p><img src='./pics/dilation.gif' alt='dilation' /></p><p></p><p>网络架构有两种，一种是前端网络，另外一种是前端网络+上下文模块，分别介绍如下：</p><ul><li>将VGG网络的最后两个pooling层给拿掉了，之后的卷积层被dilated 卷积取代。并且在pool3和pool4之间空洞卷积的空洞率=2，pool4之后的空洞卷积的空洞率=4。作者将这种架构称为前端（front-end）。</li><li>除了前端网络之外，作者还设计了一种叫做上下文模块（context module）的架构，加在前端网络之后。上下文木块中级联了多种不同空洞率的空洞卷积，使得多尺度的上下文信息可以得到整合，从而改善前端网络预测的效果。<strong>需要注意的是前端网络和上下文木块是分开训练的，因为作者在实验中发现，如果是联合在一起进行端对端的训练并不能改善性能。</strong></li></ul><p><strong>Benchmarks (VOC2012)</strong></p><table><thead><tr><th>Score</th><th>Comment</th><th>Source</th></tr></thead><tbody><tr><td>71.3</td><td>frontend</td><td>reported in the paper</td></tr><tr><td>73.5</td><td>frontend + context</td><td>reported in the paper</td></tr><tr><td>74.7</td><td>frontend + context + CRF</td><td>reported in the paper</td></tr><tr><td>75.3</td><td>frontend + context + CRF-RNN</td><td>reported in the paper</td></tr></tbody></table><p><strong>评论</strong></p><p>需要特别注意的是，网络输出的分割图并不是和原始图像大小一样的，而是其1/8，需要对输出的分割图进行线性插值才能得到最终的分割结果。这种做法也是很多其他的方法都使用的。</p><h4><a name='header-n257' class='md-header-anchor '></a>4. DeepLab(v1,v2)</h4><p><strong>论文信息</strong></p><blockquote><p><strong>v1</strong>: Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs</p><p>Submitted on 22 Dec 2014</p><p><a href='https://arxiv.org/abs/1412.7062'>Arxiv Link</a></p><p><strong>v2</strong> : DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs
Submitted on 2 Jun 2016
<a href='https://arxiv.org/abs/1606.00915'>Arxiv Link</a></p></blockquote><p><strong>主要贡献</strong></p><ol start='' ><li>使用atrous卷积，也就是后来的空洞卷积，扩大感受野，保持分辨率。</li><li>提出了atrous spatial pyramid pooling (ASPP)，整合多尺度信息。</li><li>使用全连接条件随机场（fully connected CRF)进行后处理，改善分割结果。</li></ol><p><strong>简要概述</strong></p><ol start='' ><li>空洞卷积可以在不增加参数的情况下增加感受野。</li><li>通过两种方式来进行多尺度的处理：A.将原始图像的多种尺度喂给网络进行训练。B.通过平行的不同空洞率的空洞卷积层来获得。</li><li>通过全连接条件随机场来进行后处理，以改善分割结果。</li></ol><p><img src='./pics/dilated_conv.png' alt='Selection_002' /></p><p><strong>Benchmarks (VOC2012)</strong></p><table><thead><tr><th>Score</th><th>Comment</th><th>Source</th></tr></thead><tbody><tr><td>79.7</td><td>ResNet-101 + atrous Convolutions + ASPP + CRF</td><td><a href='http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?cls=mean&challengeid=11&compid=6&submid=6103#KEY_DeepLabv2-CRF'>leaderboard</a></td></tr></tbody></table><h4><a name='header-n308' class='md-header-anchor '></a>5. RefineNet</h4><p><strong>论文信息</strong></p><blockquote><p>RefineNet: Multi-Path Refinement Networks for High-Resolution Semantic Segmentation</p><p>Submitted on 20 Nov 2016</p><p><a href='https://arxiv.org/abs/1611.06612'>Arxiv Link</a></p></blockquote><p><strong>主要贡献</strong></p><ol start='' ><li>精心设计了encoder-decoder架构中的decoder部分，使得性能提升。</li><li>整个网络的设计都遵循residual connections，网络表达能力更强，梯度更容易反向传播。</li></ol><p><strong>简要概述</strong></p><p>作者提出空洞卷积方法应用于语义分割也是有缺点的，包括：</p><ul><li>因为使用了大分辨率的feature map，因此计算代价大，并且需要大量的内存。对于这个问题，DeepLab的做法是只预测原始输入的1／8。</li></ul><p>本文提出使用encoder-decoder架构。encoder部分是RESNET-101。decoder具有RefineNet blocks，它将此前的RefineNet blocks的低分辨率特征和encoder部分高分辨率特征进行concatenate/fuse。</p><p><img src='./pics/refinenet.png' alt='refinenet' /></p><p><img src='./pics/refineblock.png' alt='refineblock' /></p><p><strong>Benchmarks (VOC2012)</strong></p><table><thead><tr><th>Score</th><th>Comment</th><th>Source</th></tr></thead><tbody><tr><td>84.2</td><td>Uses CRF, Multiscale inputs, COCO pretraining</td><td><a href='http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&compid=6#KEY_Multipath-RefineNet'>leaderboard</a></td></tr></tbody></table><h4><a name='header-n352' class='md-header-anchor '></a>6. PSPNet</h4><p><strong>论文信息</strong></p><blockquote><p>Pyramid Scene Parsing Network</p><p>Submitted on 4 Dec 2016</p><p><a href='https://arxiv.org/abs/1612.01105'>Arxiv Link</a></p></blockquote><p><strong>主要贡献</strong></p><ol><li>使用pyramid pooling整合context。</li><li>使用auxiliary loss。</li></ol><p><strong>概要</strong></p><p>骨架网络使用Resnet，并在此基础上加上pyramid pooling module。该模块用到了很多kernel大小不一的pooling 。将pooling的结果再上采样，经过concatenate进行融合。</p><p><img src='./pics/pspnet.png' alt='pspnet' /></p><p>在RESNET的第四阶段（即输入到金字塔池模块）之后，应用auxiliary loss。这种方法在别的地方也被称为intermediate supervision。</p><p><img src='./pics/auxiliaryLoss.png' alt='auxiliaryLoss' /></p><p><strong>Benchmarks (VOC2012)</strong></p><table><thead><tr><th>Score</th><th>Comment</th><th>Source</th></tr></thead><tbody><tr><td>85.4</td><td>MSCOCO pretraining, multi scale input, no CRF</td><td><a href='http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&compid=6#KEY_PSPNet'>leaderboard</a></td></tr><tr><td>82.6</td><td>no MSCOCO pretraining, multi scale input, no CRF</td><td>reported in the paper</td></tr></tbody></table><h4><a name='header-n380' class='md-header-anchor '></a>7. Large Kernel Matters</h4><p>pass</p><h4><a name='header-n367' class='md-header-anchor '></a>8. deeplab v3</h4><p>pass</p></div>
</body>
</html>